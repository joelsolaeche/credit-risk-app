{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomar como base para comparar contra otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "#Defining BASE_PATH\n",
    "BASE_PATH = os.getenv(\"/Users/carlos/Desktop/CURSOS/Anyone AI/Credit-Risk-App/dataset/\", \"/Users/carlos/Desktop/CURSOS/Anyone AI/Credit-Risk-App/dataset/\")\n",
    "\n",
    "train_file_path = os.path.join(BASE_PATH, \"X_train_data.csv\")\n",
    "y_train_file_path = os.path.join(BASE_PATH, \"y_train_data.csv\")\n",
    "val_file_path = os.path.join(BASE_PATH, \"X_val_data.csv\")\n",
    "y_val_path = os.path.join(BASE_PATH, \"y_val_data.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "\n",
    "y_train_df = pd.read_csv(y_train_file_path)\n",
    "y_train = y_train_df['TARGET_LABEL_BAD']\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "val_df = pd.read_csv(val_file_path)\n",
    "\n",
    "y_valid_df = pd.read_csv(y_val_path)\n",
    "y_valid = y_valid_df['TARGET_LABEL_BAD']\n",
    "y_valid = y_valid.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Base Model Performance ===\n",
      "Accuracy: 0.7329\n",
      "Precision: 0.46956521739130436\n",
      "Recall: 0.02027027027027027\n",
      "F1 Score: 0.0388629003238575\n",
      "ROC-AUC: 0.624247663011976\n",
      "Confusion Matrix (Base Model):\n",
      " [[7275   61]\n",
      " [2610   54]]\n",
      "                         Feature  Importance\n",
      "4            RESIDENCIAL_BOROUGH    2.472860\n",
      "3               RESIDENCIAL_CITY    2.214112\n",
      "319                     AGE_95.0    1.132746\n",
      "287                     AGE_63.0    0.953763\n",
      "182     MONTHS_IN_RESIDENCE_65.0    0.942716\n",
      "20             RESIDENCIAL_ZIP_3    0.913174\n",
      "21            PROFESSIONAL_ZIP_3    0.913174\n",
      "216          PROFESSION_CODE_5.0    0.893503\n",
      "242                     AGE_18.0    0.884501\n",
      "171     MONTHS_IN_RESIDENCE_54.0    0.880116\n",
      "317                     AGE_93.0    0.861269\n",
      "102        QUANT_DEPENDANTS_10.0    0.799360\n",
      "6    RESIDENCIAL_PHONE_AREA_CODE    0.788374\n",
      "308                     AGE_84.0    0.751453\n",
      "179     MONTHS_IN_RESIDENCE_62.0    0.740512\n",
      "225         PROFESSION_CODE_14.0    0.716047\n",
      "292                     AGE_68.0    0.682630\n",
      "169     MONTHS_IN_RESIDENCE_52.0    0.674631\n",
      "293                     AGE_69.0    0.672065\n",
      "306                     AGE_82.0    0.668436\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Train Logistic Regression without tuning\n",
    "base_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "base_model.fit(train_df, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_base = base_model.predict(val_df)\n",
    "y_prob_base = base_model.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics (Base Model)\n",
    "print(\"=== Base Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_base))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_base))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_base))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_base))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_base))\n",
    "\n",
    "# Confusion Matrix (Base Model)\n",
    "print(\"Confusion Matrix (Base Model):\\n\", confusion_matrix(y_valid, y_pred_base))\n",
    "\n",
    "# Feature Importance (Base Model)\n",
    "feature_importance_base = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': np.abs(base_model.coef_[0])\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_base.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': np.float64(5.428675439323859), 'penalty': 'l1'}\n",
      "\n",
      "=== Model Performance ===\n",
      "Accuracy: 0.7317\n",
      "Precision: 0.43448275862068964\n",
      "Recall: 0.02364864864864865\n",
      "F1 Score: 0.04485582057671769\n",
      "ROC-AUC: 0.6266952782935608\n",
      "Confusion Matrix:\n",
      " [[7254   82]\n",
      " [2601   63]]\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 50),  \n",
    "    'penalty': ['l1', 'l2']       \n",
    "}\n",
    "\n",
    "# Ensure correct solver selection\n",
    "solver = 'liblinear'  \n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression(solver=solver, max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform Grid Search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "# Fit the model on training data\n",
    "grid_search.fit(train_df, y_train)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_pred = best_model.predict(val_df)\n",
    "y_prob = best_model.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importance ===\n",
      "                       Feature  Importance\n",
      "3             RESIDENCIAL_CITY   25.908720\n",
      "21          PROFESSIONAL_ZIP_3   18.186803\n",
      "20           RESIDENCIAL_ZIP_3   12.788677\n",
      "179   MONTHS_IN_RESIDENCE_62.0    3.307447\n",
      "317                   AGE_93.0    2.875880\n",
      "240                   AGE_14.0    2.704479\n",
      "4          RESIDENCIAL_BOROUGH    2.625630\n",
      "171   MONTHS_IN_RESIDENCE_54.0    2.595274\n",
      "199  MONTHS_IN_RESIDENCE_100.0    2.591211\n",
      "216        PROFESSION_CODE_5.0    2.572411\n",
      "198   MONTHS_IN_RESIDENCE_96.0    2.471088\n",
      "193   MONTHS_IN_RESIDENCE_81.0    2.344181\n",
      "191   MONTHS_IN_RESIDENCE_78.0    2.173772\n",
      "239                    AGE_7.0    2.114371\n",
      "320                   AGE_96.0    2.079770\n",
      "319                   AGE_95.0    2.064375\n",
      "325                  AGE_106.0    2.015768\n",
      "175   MONTHS_IN_RESIDENCE_58.0    1.836031\n",
      "324                  AGE_101.0    1.832175\n",
      "201  MONTHS_IN_RESIDENCE_200.0    1.791683\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance (coefficients)\n",
    "feature_importance = pd.DataFrame({'Feature': train_df.columns, 'Importance': np.abs(best_model.coef_[0])})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "print(feature_importance.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model with an strategy to deal with imbalanced dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression with class balancing\n",
    "log_reg_balanced = LogisticRegression(solver='liblinear', class_weight='balanced', max_iter=500, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "log_reg_balanced.fit(train_df, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg_balanced.predict(val_df)\n",
    "y_prob = log_reg_balanced.predict_proba(val_df)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "train_df_balanced, y_train_balanced = smote.fit_resample(train_df, y_train)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg_smote = LogisticRegression(solver='liblinear', max_iter=500, random_state=42)\n",
    "log_reg_smote.fit(train_df_balanced, y_train_balanced)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = log_reg_smote.predict(val_df)\n",
    "y_prob_smote = log_reg_smote.predict_proba(val_df)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "train_df_under, y_train_under = rus.fit_resample(train_df, y_train)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg_under = LogisticRegression(solver='liblinear', max_iter=500, random_state=42)\n",
    "log_reg_under.fit(train_df_under, y_train_under)\n",
    "\n",
    "# Predictions\n",
    "y_pred_under = log_reg_under.predict(val_df)\n",
    "y_prob_under = log_reg_under.predict_proba(val_df)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Class Weight Balanced Model Performance ===\n",
      "Accuracy: 0.5888\n",
      "Precision: 0.34456848432803777\n",
      "Recall: 0.6024774774774775\n",
      "F1 Score: 0.43840480742966403\n",
      "ROC-AUC: 0.6249235535972177\n",
      "Confusion Matrix:\n",
      " [[4283 3053]\n",
      " [1059 1605]]\n",
      "\n",
      "=== SMOTE Oversampling Model Performance ===\n",
      "Accuracy: 0.5886\n",
      "Precision: 0.34037868780273006\n",
      "Recall: 0.5803303303303303\n",
      "F1 Score: 0.42908687205106855\n",
      "ROC-AUC: 0.6206308373531656\n",
      "Confusion Matrix:\n",
      " [[4340 2996]\n",
      " [1118 1546]]\n",
      "\n",
      "=== Undersampling Model Performance ===\n",
      "Accuracy: 0.5839\n",
      "Precision: 0.3383718419347873\n",
      "Recall: 0.5882132132132132\n",
      "F1 Score: 0.42960932145305003\n",
      "ROC-AUC: 0.6210937116232917\n",
      "Confusion Matrix:\n",
      " [[4272 3064]\n",
      " [1097 1567]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, y_prob, method):\n",
    "    print(f\"\\n=== {method} Model Performance ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_prob))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Evaluate each model\n",
    "evaluate_model(y_valid, y_pred, y_prob, \"Class Weight Balanced\")\n",
    "evaluate_model(y_valid, y_pred_smote, y_prob_smote, \"SMOTE Oversampling\")\n",
    "evaluate_model(y_valid, y_pred_under, y_prob_under, \"Undersampling\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
