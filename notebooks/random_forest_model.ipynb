{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a ramdom forest using different strategies for dealing with an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "\n",
    "#Defining BASE_PATH\n",
    "BASE_PATH = os.getenv(\"/Users/carlos/Desktop/CURSOS/Anyone AI/Credit-Risk-App/dataset/\", \"/Users/carlos/Desktop/CURSOS/Anyone AI/Credit-Risk-App/dataset/\")\n",
    "\n",
    "train_file_path = os.path.join(BASE_PATH, \"X_train_data.csv\")\n",
    "y_train_file_path = os.path.join(BASE_PATH, \"y_train_data.csv\")\n",
    "val_file_path = os.path.join(BASE_PATH, \"X_val_data.csv\")\n",
    "y_val_path = os.path.join(BASE_PATH, \"y_val_data.csv\")\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "\n",
    "y_train_df = pd.read_csv(y_train_file_path)\n",
    "y_train = y_train_df['TARGET_LABEL_BAD']\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "val_df = pd.read_csv(val_file_path)\n",
    "\n",
    "y_valid_df = pd.read_csv(y_val_path)\n",
    "y_valid = y_valid_df['TARGET_LABEL_BAD']\n",
    "y_valid = y_valid.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Default Model Performance ===\n",
      "Accuracy: 0.7312\n",
      "Precision: 0.33783783783783783\n",
      "Recall: 0.009384384384384385\n",
      "F1 Score: 0.018261504747991233\n",
      "ROC-AUC: 0.6039194694967596\n",
      "Confusion Matrix:\n",
      " [[7287   49]\n",
      " [2639   25]]\n",
      "\n",
      "=== Feature Importance (Default Model) ===\n",
      "                      Feature    Importance\n",
      "8     PERSONAL_MONTHLY_INCOME  5.755174e-02\n",
      "3            RESIDENCIAL_CITY  5.133699e-02\n",
      "20          RESIDENCIAL_ZIP_3  5.067589e-02\n",
      "21         PROFESSIONAL_ZIP_3  5.045448e-02\n",
      "2               CITY_OF_BIRTH  4.703033e-02\n",
      "..                        ...           ...\n",
      "229      PROFESSION_CODE_18.0  7.418909e-07\n",
      "186  MONTHS_IN_RESIDENCE_69.0  6.496827e-07\n",
      "178  MONTHS_IN_RESIDENCE_61.0  3.311942e-07\n",
      "183  MONTHS_IN_RESIDENCE_66.0  1.628427e-08\n",
      "194  MONTHS_IN_RESIDENCE_82.0  3.264430e-20\n",
      "\n",
      "[326 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest with default parameters and class_weight='balanced'\n",
    "rf_default = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the model\n",
    "rf_default.fit(train_df, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_default = rf_default.predict(val_df)\n",
    "y_prob_default = rf_default.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "print(\"\\n=== Default Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_default))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_default))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_default))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_default))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_default))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_default))\n",
    "\n",
    "# Feature Importance\n",
    "importances_default = rf_default.feature_importances_\n",
    "feature_importance_default = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': importances_default\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Default Model) ===\")\n",
    "print(feature_importance_default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SMOTE Model Performance ===\n",
      "Accuracy: 0.7296\n",
      "Precision: 0.44871794871794873\n",
      "Recall: 0.0656906906906907\n",
      "F1 Score: 0.114603798297315\n",
      "ROC-AUC: 0.6063711271249439\n",
      "Confusion Matrix:\n",
      " [[7121  215]\n",
      " [2489  175]]\n",
      "\n",
      "=== Feature Importance (SMOTE Model) ===\n",
      "                         Feature    Importance\n",
      "4            RESIDENCIAL_BOROUGH  4.621150e-02\n",
      "2                  CITY_OF_BIRTH  4.609565e-02\n",
      "3               RESIDENCIAL_CITY  4.142927e-02\n",
      "8        PERSONAL_MONTHLY_INCOME  4.101855e-02\n",
      "6    RESIDENCIAL_PHONE_AREA_CODE  3.633150e-02\n",
      "..                           ...           ...\n",
      "188     MONTHS_IN_RESIDENCE_71.0  4.194912e-07\n",
      "189     MONTHS_IN_RESIDENCE_72.0  3.831482e-07\n",
      "194     MONTHS_IN_RESIDENCE_82.0  1.125270e-07\n",
      "178     MONTHS_IN_RESIDENCE_61.0  9.451141e-08\n",
      "187     MONTHS_IN_RESIDENCE_70.0  2.640031e-08\n",
      "\n",
      "[326 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE for balancing the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(train_df, y_train)\n",
    "\n",
    "# Train Random Forest with the SMOTE-balanced data\n",
    "rf_smote = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "rf_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "y_pred_smote = rf_smote.predict(val_df)\n",
    "y_prob_smote = rf_smote.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics (SMOTE Model)\n",
    "print(\"\\n=== SMOTE Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_smote))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_smote))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_smote))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_smote))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_smote))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_smote))\n",
    "\n",
    "# Feature Importance (SMOTE Model)\n",
    "importances_smote = rf_smote.feature_importances_\n",
    "feature_importance_smote = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': importances_smote\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (SMOTE Model) ===\")\n",
    "print(feature_importance_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Undersampled Model Performance ===\n",
      "Accuracy: 0.5707\n",
      "Precision: 0.3246501614639397\n",
      "Recall: 0.566066066066066\n",
      "F1 Score: 0.4126419482829388\n",
      "ROC-AUC: 0.6044004064042232\n",
      "Confusion Matrix:\n",
      " [[4199 3137]\n",
      " [1156 1508]]\n",
      "\n",
      "=== Feature Importance (Undersampled Model) ===\n",
      "                      Feature  Importance\n",
      "8     PERSONAL_MONTHLY_INCOME    0.056145\n",
      "3            RESIDENCIAL_CITY    0.050321\n",
      "20          RESIDENCIAL_ZIP_3    0.050228\n",
      "21         PROFESSIONAL_ZIP_3    0.049640\n",
      "2               CITY_OF_BIRTH    0.046514\n",
      "..                        ...         ...\n",
      "197  MONTHS_IN_RESIDENCE_90.0    0.000000\n",
      "180  MONTHS_IN_RESIDENCE_63.0    0.000000\n",
      "229      PROFESSION_CODE_18.0    0.000000\n",
      "175  MONTHS_IN_RESIDENCE_58.0    0.000000\n",
      "176  MONTHS_IN_RESIDENCE_59.0    0.000000\n",
      "\n",
      "[326 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(train_df, y_train)\n",
    "\n",
    "# Train Random Forest with Undersampled data\n",
    "rf_under = RandomForestClassifier(n_jobs=-1, random_state=42, class_weight='balanced')\n",
    "rf_under.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Predictions\n",
    "y_pred_under = rf_under.predict(val_df)\n",
    "y_prob_under = rf_under.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics (Undersampled Model)\n",
    "print(\"\\n=== Undersampled Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_under))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_under))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_under))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_under))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_under))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_under))\n",
    "\n",
    "# Feature Importance (Undersampled Model)\n",
    "importances_under = rf_under.feature_importances_\n",
    "feature_importance_under = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': importances_under\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Undersampled Model) ===\")\n",
    "print(feature_importance_under)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters from RandomizedSearchCV: {'bootstrap': False, 'max_depth': 38, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 196}\n",
      "\n",
      "=== Tuned Model Performance ===\n",
      "Accuracy: 0.7245\n",
      "Precision: 0.4077079107505071\n",
      "Recall: 0.07545045045045046\n",
      "F1 Score: 0.12733607855559076\n",
      "ROC-AUC: 0.6128511622309333\n",
      "Confusion Matrix:\n",
      " [[7044  292]\n",
      " [2463  201]]\n",
      "\n",
      "=== Feature Importance (Tuned Model) ===\n",
      "                         Feature  Importance\n",
      "4            RESIDENCIAL_BOROUGH    0.054540\n",
      "2                  CITY_OF_BIRTH    0.050331\n",
      "6    RESIDENCIAL_PHONE_AREA_CODE    0.043597\n",
      "1                            SEX    0.040814\n",
      "3               RESIDENCIAL_CITY    0.038174\n",
      "..                           ...         ...\n",
      "177     MONTHS_IN_RESIDENCE_60.0    0.000000\n",
      "176     MONTHS_IN_RESIDENCE_59.0    0.000000\n",
      "175     MONTHS_IN_RESIDENCE_58.0    0.000000\n",
      "198     MONTHS_IN_RESIDENCE_96.0    0.000000\n",
      "178     MONTHS_IN_RESIDENCE_61.0    0.000000\n",
      "\n",
      "[326 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define hyperparameter search space\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees in the forest\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for best split\n",
    "    'max_depth': randint(10, 50),  # Maximum depth of the tree\n",
    "    'min_samples_split': randint(2, 10),  # Minimum samples required to split a node\n",
    "    'min_samples_leaf': randint(1, 10),  # Minimum samples required at leaf node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# Perform Randomized Search with 5-fold cross-validation\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "                                   param_distributions=param_dist, n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the model using SMOTE data (for example)\n",
    "random_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best parameters from RandomizedSearchCV\n",
    "print(\"Best Parameters from RandomizedSearchCV:\", random_search.best_params_)\n",
    "\n",
    "# Predictions (Tuned Model)\n",
    "y_pred_tuned = random_search.best_estimator_.predict(val_df)\n",
    "y_prob_tuned = random_search.best_estimator_.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics (Tuned Model)\n",
    "print(\"\\n=== Tuned Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_tuned))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_tuned))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_tuned))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_tuned))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_tuned))\n",
    "\n",
    "# Confusion Matrix (Tuned Model)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_tuned))\n",
    "\n",
    "# Feature Importance (Tuned Model)\n",
    "importances_tuned = random_search.best_estimator_.feature_importances_\n",
    "feature_importance_tuned = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': importances_tuned\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Tuned Model) ===\")\n",
    "print(feature_importance_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Model Performance ===\n",
      "Accuracy: 0.7245\n",
      "Precision: 0.4077079107505071\n",
      "Recall: 0.07545045045045046\n",
      "F1 Score: 0.12733607855559076\n",
      "ROC-AUC: 0.6128511622309333\n",
      "Confusion Matrix:\n",
      " [[7044  292]\n",
      " [2463  201]]\n",
      "\n",
      "=== Feature Importance (Final Model) ===\n",
      "                         Feature  Importance\n",
      "4            RESIDENCIAL_BOROUGH    0.054540\n",
      "2                  CITY_OF_BIRTH    0.050331\n",
      "6    RESIDENCIAL_PHONE_AREA_CODE    0.043597\n",
      "1                            SEX    0.040814\n",
      "3               RESIDENCIAL_CITY    0.038174\n",
      "..                           ...         ...\n",
      "177     MONTHS_IN_RESIDENCE_60.0    0.000000\n",
      "176     MONTHS_IN_RESIDENCE_59.0    0.000000\n",
      "175     MONTHS_IN_RESIDENCE_58.0    0.000000\n",
      "198     MONTHS_IN_RESIDENCE_96.0    0.000000\n",
      "178     MONTHS_IN_RESIDENCE_61.0    0.000000\n",
      "\n",
      "[326 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with best parameters\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Fit the final model on the full balanced dataset (e.g., SMOTE data)\n",
    "best_rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions (Final Model)\n",
    "y_pred_final = best_rf.predict(val_df)\n",
    "y_prob_final = best_rf.predict_proba(val_df)[:, 1]\n",
    "\n",
    "# Performance Metrics (Final Model)\n",
    "print(\"\\n=== Final Model Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_valid, y_pred_final))\n",
    "print(\"Precision:\", precision_score(y_valid, y_pred_final))\n",
    "print(\"Recall:\", recall_score(y_valid, y_pred_final))\n",
    "print(\"F1 Score:\", f1_score(y_valid, y_pred_final))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_valid, y_prob_final))\n",
    "\n",
    "# Confusion Matrix (Final Model)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_valid, y_pred_final))\n",
    "\n",
    "# Feature Importance (Final Model)\n",
    "importances_final = best_rf.feature_importances_\n",
    "feature_importance_final = pd.DataFrame({\n",
    "    'Feature': train_df.columns,\n",
    "    'Importance': importances_final\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Final Model) ===\")\n",
    "print(feature_importance_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
